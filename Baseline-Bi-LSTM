{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8670858,"sourceType":"datasetVersion","datasetId":5196493}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nnp.random.seed(0)\nplt.style.use(\"ggplot\")\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Embedding, LSTM, Bidirectional, Dropout, InputLayer, TimeDistributed\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split, KFold\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n# Load dataset\ndata = pd.read_csv(\"/kaggle/input/new-ner-csv/new_ner_karhutla - new_ner_karhutla (5).csv\", encoding=\"latin1\")\ndata = data.fillna(method=\"ffill\")\ndata[\"Tag\"].fillna(\"O\", inplace=True)\n\ndata.head(20)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-12T06:25:13.043373Z","iopub.execute_input":"2024-06-12T06:25:13.044097Z","iopub.status.idle":"2024-06-12T06:25:27.929804Z","shell.execute_reply.started":"2024-06-12T06:25:13.044065Z","shell.execute_reply":"2024-06-12T06:25:27.928674Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-06-12 06:25:16.131441: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-12 06:25:16.131576: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-12 06:25:16.293054: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/tmp/ipykernel_33/235235638.py:21: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  data = data.fillna(method=\"ffill\")\n/tmp/ipykernel_33/235235638.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  data[\"Tag\"].fillna(\"O\", inplace=True)\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"    Sentence         Word    Tag\n0          1     Penulis:      O\n1          1         Vika  B-per\n2          1       Azkiya  I-per\n3          1        Dihni  I-per\n4          1      Editor:  I-per\n5          1         Aria  B-per\n6          1           W.  B-per\n7          2   Yudhistira  I-per\n8          2   11/1/2022,  B-tim\n9          2        10.20  I-tim\n10         2  WIB\\n\\nLuas  I-tim\n11         2        areal  I-tim\n12         2    kebakaran  I-tim\n13         2        hutan  I-tim\n14         2          dan  I-tim\n15         2        lahan  I-tim\n16         2   (karhutla)  I-tim\n17         2           di  I-tim\n18         2    Indonesia  B-geo\n19         2    sepanjang  B-geo","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence</th>\n      <th>Word</th>\n      <th>Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Penulis:</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Vika</td>\n      <td>B-per</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Azkiya</td>\n      <td>I-per</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Dihni</td>\n      <td>I-per</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Editor:</td>\n      <td>I-per</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>Aria</td>\n      <td>B-per</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>W.</td>\n      <td>B-per</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2</td>\n      <td>Yudhistira</td>\n      <td>I-per</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2</td>\n      <td>11/1/2022,</td>\n      <td>B-tim</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2</td>\n      <td>10.20</td>\n      <td>I-tim</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2</td>\n      <td>WIB\\n\\nLuas</td>\n      <td>I-tim</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2</td>\n      <td>areal</td>\n      <td>I-tim</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2</td>\n      <td>kebakaran</td>\n      <td>I-tim</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2</td>\n      <td>hutan</td>\n      <td>I-tim</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>2</td>\n      <td>dan</td>\n      <td>I-tim</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2</td>\n      <td>lahan</td>\n      <td>I-tim</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2</td>\n      <td>(karhutla)</td>\n      <td>I-tim</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2</td>\n      <td>di</td>\n      <td>I-tim</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2</td>\n      <td>Indonesia</td>\n      <td>B-geo</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2</td>\n      <td>sepanjang</td>\n      <td>B-geo</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Preprocess dataset\nwords = list(set(data[\"Word\"].values))\nwords.append(\"ENDPAD\")\nnum_words = len(words)\n\ntags = list(set(data[\"Tag\"].values))\nnum_tags = len(tags)\n\nclass SentenceGetter(object):\n    def __init__(self, data):\n        self.n_sent = 1\n        self.data = data\n        self.empty = False\n        agg_func = lambda s: [(w, t) for w,  t in zip(s[\"Word\"].values.tolist(), s[\"Tag\"].values.tolist())]\n        self.grouped = self.data.groupby(\"Sentence\").apply(agg_func)\n        self.sentences = [s for s in self.grouped]\n\n    def get_next(self):\n        try:\n            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n            self.n_sent += 1\n            return s\n        except:\n            return None\n\ngetter = SentenceGetter(data)\nsentences = getter.sentences\n\nword2idx = {w: i + 1 for i, w in enumerate(words)}\ntag2idx = {t: i for i, t in enumerate(tags)}\n\nmax_len = 50\n\nX = [[word2idx[w[0]] for w in s] for s in sentences]\nX = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=num_words-1)\n\ny = [[tag2idx[w[1]] for w in s] for s in sentences]\ny = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n\n# Convert labels to one-hot encoding\ny = [to_categorical(i, num_classes=num_tags) for i in y]\n\n# Define Bi-LSTM model\ndef create_bilstm_model():\n    model = Sequential([\n        InputLayer(input_shape=(max_len,)),\n        Embedding(input_dim=num_words, output_dim=50, input_length=max_len),\n        SpatialDropout1D(0.1),\n        Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1)),\n        TimeDistributed(Dense(num_tags, activation=\"softmax\"))\n    ])\n    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    return model\n\n# K-Fold Cross-Validation\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\nfold_no = 1\ncv_results = []\n\nfor train_index, val_index in kf.split(X):\n    x_train, x_val = X[train_index], X[val_index]\n    y_train, y_val = np.array(y)[train_index], np.array(y)[val_index]\n\n    model = create_bilstm_model()\n\n    history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val), verbose=1)\n\n    # Evaluate model\n    val_pred = model.predict(x_val)\n    val_pred_labels = np.argmax(val_pred, axis=-1)\n    val_true_labels = np.argmax(y_val, axis=-1)\n\n    precision = precision_score(val_true_labels.flatten(), val_pred_labels.flatten(), average=\"macro\")\n    recall = recall_score(val_true_labels.flatten(), val_pred_labels.flatten(), average=\"macro\")\n    f1 = f1_score(val_true_labels.flatten(), val_pred_labels.flatten(), average=\"macro\")\n\n    cv_results.append({\n        \"fold\": fold_no,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1\": f1,\n        \"accuracy\": history.history[\"val_accuracy\"][-1],\n        \"loss\": history.history[\"val_loss\"][-1]\n    })\n\n    fold_no += 1\n\n# Convert results to DataFrame and display\ncv_results_df = pd.DataFrame(cv_results)\ncv_results_df\n\n# Plot performance metrics\nplt.figure(figsize=(12, 6))\nplt.plot(cv_results_df[\"fold\"], cv_results_df[\"accuracy\"], marker='o', label='Validation Accuracy')\nplt.plot(cv_results_df[\"fold\"], cv_results_df[\"loss\"], marker='o', label='Validation Loss')\nplt.title('Validation Accuracy and Loss for Each Fold')\nplt.xlabel('Fold')\nplt.ylabel('Value')\nplt.legend()\nplt.show()\n\n# Robustness Testing Functions\ndef replace_synonyms(text, synonyms_dict):\n    words = text.split()\n    new_text = \" \".join([synonyms_dict.get(word, word) for word in words])\n    return new_text\n\ndef introduce_typos(text, typo_rate=0.1):\n    words = text.split()\n    new_words = []\n    for word in words:\n        if np.random.rand() < typo_rate:\n            index = np.random.randint(0, len(word))\n            typo_char = np.random.choice(list('abcdefghijklmnopqrstuvwxyz'))\n            new_word = word[:index] + typo_char + word[index+1:]\n            new_words.append(new_word)\n        else:\n            new_words.append(word)\n    return \" \".join(new_words)\n\ndef shuffle_word_order(text):\n    words = text.split()\n    random.shuffle(words)\n    return \" \".join(words)\n\ndef add_noise(text, noise_level=0.1):\n    noisy_text = list(text)\n    num_chars = int(len(noisy_text) * noise_level)\n    for _ in range(num_chars):\n        index = random.randint(0, len(noisy_text) - 1)\n        noisy_text[index] = random.choice('abcdefghijklmnopqrstuvwxyz')\n    return \"\".join(noisy_text)\n\ndef paraphrase(text):\n    paraphrases = {\n        \"The forest fire caused significant damage to the area.\": \"Significant damage was caused by the forest fire to the area.\"\n    }\n    return paraphrases.get(text, text)\n\n# Robustness Evaluation\ndef evaluate_robustness(model, test_texts, test_labels, variation_func, *args):\n    varied_texts = [variation_func(text, *args) for text in test_texts]\n    varied_sequences = [[word2idx.get(w, num_words-1) for w in text.split()] for text in varied_texts]\n    varied_sequences = pad_sequences(maxlen=max_len, sequences=varied_sequences, padding=\"post\", value=num_words-1)\n    predictions = model.predict(varied_sequences)\n    pred_labels = np.argmax(predictions, axis=-1)\n    true_labels = [[tag2idx.get(w, tag2idx[\"O\"]) for w in label.split()] for label in test_labels]\n\n    precision = precision_score(np.array(true_labels).flatten(), pred_labels.flatten(), average=\"macro\")\n    recall = recall_score(np.array(true_labels).flatten(), pred_labels.flatten(), average=\"macro\")\n    f1 = f1_score(np.array(true_labels).flatten(), pred_labels.flatten(), average=\"macro\")\n\n    return precision, recall, f1\n\n# Example usage of robustness evaluation\nsynonyms_dict = {'fire': 'blaze', 'forest': 'woodland'}\ntest_texts = [\"The forest fire caused significant damage to the area.\"]\ntest_labels = [\"O O O O O B-LOC O O\"]\n\n# Evaluate on original data\noriginal_precision, original_recall, original_f1 = evaluate_robustness(model, test_texts, test_labels, lambda x: x)\nprint(f\"Original - Precision: {original_precision}, Recall: {original_recall}, F1: {original_f1}\")\n\n# Evaluate on synonym replaced data\nsynonym_precision, synonym_recall, synonym_f1 = evaluate_robustness(model, test_texts, test_labels, replace_synonyms, synonyms_dict)\nprint(f\"Synonym - Precision: {synonym_precision}, Recall: {synonym_recall}, F1: {synonym_f1}\")\n\n# Evaluate on data with typos\ntypo_precision, typo_recall, typo_f1 = evaluate_robustness(model, test_texts, test_labels, introduce_typos)\nprint(f\"Typos - Precision: {typo_precision}, Recall: {typo_recall}, F1: {typo_f1}\")\n\n# Evaluate on shuffled word order data\nshuffle_precision, shuffle_recall, shuffle_f1 = evaluate_robustness(model, test_texts, test_labels, shuffle_word_order)\nprint(f\"Shuffled Word Order - Precision: {shuffle_precision}, Recall: {shuffle_recall}, F1: {shuffle_f1}\")\n\n# Evaluate on noisy data\nnoise_precision, noise_recall, noise_f1 = evaluate_robustness(model, test_texts, test_labels, add_noise)\nprint(f\"Noise - Precision: {noise_precision}, Recall: {noise_recall}, F1: {noise_f1}\")\n\n# Evaluate on paraphrased data\nparaphrase_precision, paraphrase_recall, paraphrase_f1 = evaluate_robustness(model, test_texts, test_labels, paraphrase)\nprint(f\"Paraphrase - Precision: {paraphrase_precision}, Recall: {paraphrase_recall}, F1: {paraphrase_f1}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-12T06:25:27.931663Z","iopub.execute_input":"2024-06-12T06:25:27.931997Z","iopub.status.idle":"2024-06-12T06:25:29.309357Z","shell.execute_reply.started":"2024-06-12T06:25:27.931969Z","shell.execute_reply":"2024-06-12T06:25:29.307921Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/1245539901.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  self.grouped = self.data.groupby(\"Sentence\").apply(agg_func)\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m x_train, x_val \u001b[38;5;241m=\u001b[39m X[train_index], X[val_index]\n\u001b[1;32m     62\u001b[0m y_train, y_val \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y)[train_index], np\u001b[38;5;241m.\u001b[39marray(y)[val_index]\n\u001b[0;32m---> 64\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_bilstm_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(x_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(x_val, y_val), verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Evaluate model\u001b[39;00m\n","Cell \u001b[0;32mIn[2], line 48\u001b[0m, in \u001b[0;36mcreate_bilstm_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_bilstm_model\u001b[39m():\n\u001b[1;32m     45\u001b[0m     model \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[1;32m     46\u001b[0m         InputLayer(input_shape\u001b[38;5;241m=\u001b[39m(max_len,)),\n\u001b[1;32m     47\u001b[0m         Embedding(input_dim\u001b[38;5;241m=\u001b[39mnum_words, output_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, input_length\u001b[38;5;241m=\u001b[39mmax_len),\n\u001b[0;32m---> 48\u001b[0m         \u001b[43mSpatialDropout1D\u001b[49m(\u001b[38;5;241m0.1\u001b[39m),\n\u001b[1;32m     49\u001b[0m         Bidirectional(LSTM(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, recurrent_dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)),\n\u001b[1;32m     50\u001b[0m         TimeDistributed(Dense(num_tags, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     51\u001b[0m     ])\n\u001b[1;32m     52\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n","\u001b[0;31mNameError\u001b[0m: name 'SpatialDropout1D' is not defined"],"ename":"NameError","evalue":"name 'SpatialDropout1D' is not defined","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}